{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Scenario B-ARFF==========\n",
      "Scenario B-ARFF_60s : (15515, 24)\n",
      "Scenario B-ARFF_30s-AllinOne : (14651, 24)\n",
      "Scenario B-ARFF_120s : (10782, 24)\n",
      "Scenario B-ARFF_60s-AllinOne : (15515, 24)\n",
      "Scenario B-ARFF_120s-AllinOne : (10782, 24)\n",
      "Scenario B-ARFF_30s : (14651, 24)\n",
      "Scenario B-ARFF_15s-AllinOne : (18758, 24)\n",
      "Scenario B-ARFF_15s : (18758, 24)\n",
      "==========Scenario A2-ARFF==========\n",
      "Scenario A2-ARFF_30s-NO-VPN : (6917 , 24)\n",
      "Scenario A2-ARFF_30s-VPN : (7734 , 24)\n",
      "Scenario A2-ARFF_15s-VPN : (9793 , 24)\n",
      "Scenario A2-ARFF_120s-NO-VPN : (5151 , 24)\n",
      "Scenario A2-ARFF_120s-VPN : (5631 , 24)\n",
      "Scenario A2-ARFF_60s-VPN : (6935 , 24)\n",
      "Scenario A2-ARFF_15s-NO-VPN : (8965 , 24)\n",
      "Scenario A2-ARFF_60s-NO-VPN : (8580 , 24)\n",
      "==========Scenario A1-ARFF==========\n",
      "Scenario A1-ARFF_60s-VPN : (15515, 24)\n",
      "Scenario A1-ARFF_15s-VPN : (18758, 24)\n",
      "Scenario A1-ARFF_120s-VPN : (10782, 24)\n",
      "Scenario A1-ARFF_30s-VPN : (14651, 24)\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = './ISCX-VPN-NonVPN_data/'\n",
    "all_df = {}\n",
    "all_source = {}\n",
    "\n",
    "for sub_folder in os.listdir(folder_path):\n",
    "  full_path = os.path.join(folder_path, sub_folder)\n",
    "  if os.path.isdir(full_path):\n",
    "    all_folder_df = []\n",
    "    all_folder_source = []\n",
    "    for filename in os.listdir(full_path):\n",
    "      if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(full_path, filename)\n",
    "        extracted = filename.replace('TimeBasedFeatures-Dataset-', '').replace('.csv', '')\n",
    "        try:\n",
    "          df = pd.read_csv(file_path)\n",
    "          all_folder_df.append(df)\n",
    "          all_folder_source.append(extracted)\n",
    "        except Exception as e:\n",
    "          print(f\"⚠️ 에러 발생: {sub_folder}/{extracted} → {e}\")\n",
    "          continue\n",
    "    all_df[sub_folder] = all_folder_df\n",
    "    all_source[sub_folder] = all_folder_source\n",
    "\n",
    "for sub_folder in all_df:\n",
    "  print(f\"=========={sub_folder}==========\")\n",
    "  for df, source in zip(all_df[sub_folder], all_source[sub_folder]):\n",
    "    shape = f\"({df.shape[0]:<5}, {df.shape[1]})\"\n",
    "    print(f\"{source:<12} : {shape}\")\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Scenario B-ARFF==========\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "==========Scenario A2-ARFF==========\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "==========Scenario A1-ARFF==========\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n",
      "['class1']\n"
     ]
    }
   ],
   "source": [
    "for sub_folder in all_df:\n",
    "    print(f\"=========={sub_folder}==========\")\n",
    "    for df, source in zip(all_df[sub_folder], all_source[sub_folder]):\n",
    "        non_numeric_cols = df.select_dtypes(exclude='number').columns.tolist()\n",
    "        print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 매핑 함수 선언\n",
    "## (범주형 데이터 숫자형으로 변환)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df_work: pd.DataFrame):\n",
    "  start = len(df_work)\n",
    "  \n",
    "  df_work.drop_duplicates(inplace=True)\n",
    "  \n",
    "  finish = len(df_work)\n",
    "  print(f\"중복 데이터 처리 : {start} - {start-finish} -> {finish}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 누락 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_missing(df_work: pd.DataFrame):\n",
    "  from sklearn.impute import KNNImputer\n",
    "\n",
    "  start_missing = df_work.isnull().sum()\n",
    "  start_missing = start_missing[start_missing > 0].to_dict()\n",
    "\n",
    "  numeric_cols = df_work.select_dtypes(include='number').columns\n",
    "  df_numeric = df_work[numeric_cols]\n",
    "\n",
    "  imputer = KNNImputer(n_neighbors=10)\n",
    "  df_imputed_numeric = pd.DataFrame(imputer.fit_transform(df_numeric), columns=numeric_cols, index=df_numeric.index)\n",
    "\n",
    "  df_work[numeric_cols] = df_imputed_numeric\n",
    "  \n",
    "  finish_missing = df_work.isnull().sum()\n",
    "  finish_missing = finish_missing[finish_missing > 0].to_dict()\n",
    "  print(f\"누락 데이터 처리 후: {start_missing} -> {finish_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_outlier(df_work: pd.DataFrame):\n",
    "    first = len(df_work)\n",
    "    numeric_cols = df_work.select_dtypes(include='number').columns\n",
    "    classes = df_work['class1'].unique()\n",
    "\n",
    "    cleaned_parts = []\n",
    "    SUM = 0\n",
    "\n",
    "    for cls in classes:\n",
    "        df_cls = df_work[df_work['class1'] == cls].copy()\n",
    "        outlier_indices = set()\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df_cls[col].quantile(0.25)\n",
    "            Q3 = df_cls[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            outliers = df_cls[(df_cls[col] < lower_bound) | (df_cls[col] > upper_bound)].index\n",
    "            outlier_indices.update(outliers)\n",
    "\n",
    "        df_cls.drop(index=outlier_indices, inplace=True)\n",
    "        cleaned_parts.append(df_cls)\n",
    "\n",
    "        SUM += len(outlier_indices)\n",
    "\n",
    "    # inplace 갱신\n",
    "    df_work.drop(df_work.index, inplace=True)\n",
    "    df_work.reset_index(drop=True, inplace=True)\n",
    "    df_work[:] = pd.concat(cleaned_parts).reset_index(drop=True)\n",
    "\n",
    "    print(f\"전체 처리 후: {first} - {SUM} → {len(df_work)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Scenario B-ARFF==========\n",
      "=====================================\n",
      "Scenario B-ARFF_60s - Preprocess\n",
      "중복 데이터 처리 : 15515 - 786 -> 14729\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 14729 - 8815 → 5914\n",
      "=====================================\n",
      "Scenario B-ARFF_30s-AllinOne - Preprocess\n",
      "중복 데이터 처리 : 14651 - 1027 -> 13624\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 13624 - 7810 → 5814\n",
      "=====================================\n",
      "Scenario B-ARFF_120s - Preprocess\n",
      "중복 데이터 처리 : 10782 - 1193 -> 9589\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 9589 - 6105 → 3484\n",
      "=====================================\n",
      "Scenario B-ARFF_60s-AllinOne - Preprocess\n",
      "중복 데이터 처리 : 15515 - 817 -> 14698\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 14698 - 8910 → 5788\n",
      "=====================================\n",
      "Scenario B-ARFF_120s-AllinOne - Preprocess\n",
      "중복 데이터 처리 : 10782 - 1212 -> 9570\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 9570 - 5960 → 3610\n",
      "=====================================\n",
      "Scenario B-ARFF_30s - Preprocess\n",
      "중복 데이터 처리 : 14651 - 1013 -> 13638\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 13638 - 8005 → 5633\n",
      "=====================================\n",
      "Scenario B-ARFF_15s-AllinOne - Preprocess\n",
      "중복 데이터 처리 : 18758 - 706 -> 18052\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 18052 - 10543 → 7509\n",
      "=====================================\n",
      "Scenario B-ARFF_15s - Preprocess\n",
      "중복 데이터 처리 : 18758 - 684 -> 18074\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 18074 - 9988 → 8086\n",
      "=====================================\n",
      "==========Scenario A2-ARFF==========\n",
      "=====================================\n",
      "Scenario A2-ARFF_30s-NO-VPN - Preprocess\n",
      "중복 데이터 처리 : 6917 - 223 -> 6694\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 6694 - 3782 → 2912\n",
      "=====================================\n",
      "Scenario A2-ARFF_30s-VPN - Preprocess\n",
      "중복 데이터 처리 : 7734 - 790 -> 6944\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 6944 - 3756 → 3188\n",
      "=====================================\n",
      "Scenario A2-ARFF_15s-VPN - Preprocess\n",
      "중복 데이터 처리 : 9793 - 413 -> 9380\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 9380 - 4988 → 4392\n",
      "=====================================\n",
      "Scenario A2-ARFF_120s-NO-VPN - Preprocess\n",
      "중복 데이터 처리 : 5151 - 210 -> 4941\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 4941 - 3140 → 1801\n",
      "=====================================\n",
      "Scenario A2-ARFF_120s-VPN - Preprocess\n",
      "중복 데이터 처리 : 5631 - 983 -> 4648\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 4648 - 2767 → 1881\n",
      "=====================================\n",
      "Scenario A2-ARFF_60s-VPN - Preprocess\n",
      "중복 데이터 처리 : 6935 - 412 -> 6523\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 6523 - 3476 → 3047\n",
      "=====================================\n",
      "Scenario A2-ARFF_15s-NO-VPN - Preprocess\n",
      "중복 데이터 처리 : 8965 - 271 -> 8694\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 8694 - 4408 → 4286\n",
      "=====================================\n",
      "Scenario A2-ARFF_60s-NO-VPN - Preprocess\n",
      "중복 데이터 처리 : 8580 - 374 -> 8206\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 8206 - 4881 → 3325\n",
      "=====================================\n",
      "==========Scenario A1-ARFF==========\n",
      "=====================================\n",
      "Scenario A1-ARFF_60s-VPN - Preprocess\n",
      "중복 데이터 처리 : 15515 - 838 -> 14677\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 14677 - 12132 → 2545\n",
      "=====================================\n",
      "Scenario A1-ARFF_15s-VPN - Preprocess\n",
      "중복 데이터 처리 : 18758 - 720 -> 18038\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 18038 - 13802 → 4236\n",
      "=====================================\n",
      "Scenario A1-ARFF_120s-VPN - Preprocess\n",
      "중복 데이터 처리 : 10782 - 1257 -> 9525\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 9525 - 7735 → 1790\n",
      "=====================================\n",
      "Scenario A1-ARFF_30s-VPN - Preprocess\n",
      "중복 데이터 처리 : 14651 - 1041 -> 13610\n",
      "누락 데이터 처리 후: {} -> {}\n",
      "전체 처리 후: 13610 - 10610 → 3000\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# 데이터 젙처리\n",
    "all_df_preprocess = {}\n",
    "for sub_folder in all_df:\n",
    "    all_folder_df_preprocess = []\n",
    "    print(f\"=========={sub_folder}==========\")\n",
    "    for df, source in zip(all_df[sub_folder], all_source[sub_folder]):\n",
    "        df_preprocess = df.copy()\n",
    "        print(\"=====================================\")\n",
    "        print(f\"{source} - Preprocess\")\n",
    "        drop_duplicates(df_preprocess)\n",
    "        processing_missing(df_preprocess)\n",
    "        processing_outlier(df_preprocess)\n",
    "        all_folder_df_preprocess.append(df_preprocess)\n",
    "    print(\"=====================================\")\n",
    "    all_df_preprocess[sub_folder] = all_folder_df_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 후 shape 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Scenario B-ARFF==========\n",
      "Scenario B-ARFF_60s : (15515, 24) -> (5914 , 24)\n",
      "Scenario B-ARFF_30s-AllinOne : (14651, 24) -> (5814 , 24)\n",
      "Scenario B-ARFF_120s : (10782, 24) -> (3484 , 24)\n",
      "Scenario B-ARFF_60s-AllinOne : (15515, 24) -> (5788 , 24)\n",
      "Scenario B-ARFF_120s-AllinOne : (10782, 24) -> (3610 , 24)\n",
      "Scenario B-ARFF_30s : (14651, 24) -> (5633 , 24)\n",
      "Scenario B-ARFF_15s-AllinOne : (18758, 24) -> (7509 , 24)\n",
      "Scenario B-ARFF_15s : (18758, 24) -> (8086 , 24)\n",
      "==========Scenario A2-ARFF==========\n",
      "Scenario A2-ARFF_30s-NO-VPN : (6917 , 24) -> (2912 , 24)\n",
      "Scenario A2-ARFF_30s-VPN : (7734 , 24) -> (3188 , 24)\n",
      "Scenario A2-ARFF_15s-VPN : (9793 , 24) -> (4392 , 24)\n",
      "Scenario A2-ARFF_120s-NO-VPN : (5151 , 24) -> (1801 , 24)\n",
      "Scenario A2-ARFF_120s-VPN : (5631 , 24) -> (1881 , 24)\n",
      "Scenario A2-ARFF_60s-VPN : (6935 , 24) -> (3047 , 24)\n",
      "Scenario A2-ARFF_15s-NO-VPN : (8965 , 24) -> (4286 , 24)\n",
      "Scenario A2-ARFF_60s-NO-VPN : (8580 , 24) -> (3325 , 24)\n",
      "==========Scenario A1-ARFF==========\n",
      "Scenario A1-ARFF_60s-VPN : (15515, 24) -> (2545 , 24)\n",
      "Scenario A1-ARFF_15s-VPN : (18758, 24) -> (4236 , 24)\n",
      "Scenario A1-ARFF_120s-VPN : (10782, 24) -> (1790 , 24)\n",
      "Scenario A1-ARFF_30s-VPN : (14651, 24) -> (3000 , 24)\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "for sub_folder in all_df_preprocess:\n",
    "  print(f\"=========={sub_folder}==========\")\n",
    "  for df, df_preprocess, source in zip(all_df[sub_folder], all_df_preprocess[sub_folder], all_source[sub_folder]):\n",
    "    before = f\"({df.shape[0]:<5}, {df.shape[1]})\"\n",
    "    after = f\"({df_preprocess.shape[0]:<5}, {df_preprocess.shape[1]})\"\n",
    "    print(f\"{source:<15} : {before} -> {after}\")\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario B-ARFF_60s.csv\n",
      "Scenario B-ARFF_30s-AllinOne.csv\n",
      "Scenario B-ARFF_120s.csv\n",
      "Scenario B-ARFF_60s-AllinOne.csv\n",
      "Scenario B-ARFF_120s-AllinOne.csv\n",
      "Scenario B-ARFF_30s.csv\n",
      "Scenario B-ARFF_15s-AllinOne.csv\n",
      "Scenario B-ARFF_15s.csv\n",
      "Scenario A2-ARFF_30s-NO-VPN.csv\n",
      "Scenario A2-ARFF_30s-VPN.csv\n",
      "Scenario A2-ARFF_15s-VPN.csv\n",
      "Scenario A2-ARFF_120s-NO-VPN.csv\n",
      "Scenario A2-ARFF_120s-VPN.csv\n",
      "Scenario A2-ARFF_60s-VPN.csv\n",
      "Scenario A2-ARFF_15s-NO-VPN.csv\n",
      "Scenario A2-ARFF_60s-NO-VPN.csv\n",
      "Scenario A1-ARFF_60s-VPN.csv\n",
      "Scenario A1-ARFF_15s-VPN.csv\n",
      "Scenario A1-ARFF_120s-VPN.csv\n",
      "Scenario A1-ARFF_30s-VPN.csv\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"preprocessed_data\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for sub_folder in all_df_preprocess:\n",
    "    for idx, (df_preprocess, source) in enumerate(zip(all_df_preprocess[sub_folder], all_source[sub_folder])):\n",
    "        filename = f\"{source}.csv\"\n",
    "        print(filename)\n",
    "        filepath = os.path.join(save_dir, sub_folder, filename)\n",
    "        os.makedirs(os.path.join(save_dir, sub_folder), exist_ok=True)\n",
    "        df_preprocess.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
