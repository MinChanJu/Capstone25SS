{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'Python 3.13.2'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31m다음 명령어를 실행하여 Python 환경에 'ipykernel'을(를) 설치합니다. \n",
      "\u001b[1;31m 명령: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "folder_path = './ISCX-VPN-NonVPN-2016 CSVs/'\n",
    "all_df = {}\n",
    "all_source = {}\n",
    "\n",
    "for sub_folder in os.listdir(folder_path):\n",
    "  full_path = os.path.join(folder_path, sub_folder)\n",
    "  if os.path.isdir(full_path):\n",
    "    all_folder_df = []\n",
    "    all_folder_source = []\n",
    "    for filename in os.listdir(full_path):\n",
    "      if filename.endswith('.arff'):\n",
    "        file_path = os.path.join(full_path, filename)\n",
    "        extracted = filename.replace('TimeBasedFeatures-Dataset-', '').replace('.arff', '')\n",
    "        try:\n",
    "          data, _ = arff.loadarff(file_path)\n",
    "          df = pd.DataFrame(data)\n",
    "          df['class1'] = df['class1'].str.decode('utf-8')\n",
    "          all_folder_df.append(df)\n",
    "          all_folder_source.append(extracted)\n",
    "        except Exception as e:\n",
    "          print(f\"⚠️ 에러 발생: {sub_folder}/{extracted} → {e}\")\n",
    "          continue\n",
    "    all_df[sub_folder] = all_folder_df\n",
    "    all_source[sub_folder] = all_folder_source\n",
    "  \n",
    "for sub_folder in all_df:\n",
    "  print(f\"=========={sub_folder}==========\")\n",
    "  for df, source in zip(all_df[sub_folder], all_source[sub_folder]):\n",
    "    shape = f\"({df.shape[0]:<5}, {df.shape[1]})\"\n",
    "    print(f\"{source:<12} : {shape}\")\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 매핑 함수 선언\n",
    "## (범주형 데이터 숫자형으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "def col_mapping(df_work: pd.DataFrame):\n",
    "  non_numeric_cols = df_work.select_dtypes(exclude=['number']).columns\n",
    "  total = {}\n",
    "  for col in non_numeric_cols:\n",
    "    normal = {}\n",
    "    reverse = {}\n",
    "    idx = 0\n",
    "    for uni in df[col].unique():\n",
    "      if (pd.isna(uni)): continue\n",
    "      normal[uni] = idx\n",
    "      reverse[idx] = uni\n",
    "      idx += 1\n",
    "    total[col] = {\"normal\": normal, \"reverse\": reverse}\n",
    "  return total\n",
    "\n",
    "def numeric_mapping(df_work: pd.DataFrame, total: dict, reverse: bool):\n",
    "  cla = \"normal\"\n",
    "  if (reverse):\n",
    "    for col in total:\n",
    "      df_work[col] = df_work[col].round()\n",
    "    cla = \"reverse\"\n",
    "  for col in total:\n",
    "    df_work[col] = df_work[col].map(total[col][cla])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df_work: pd.DataFrame):\n",
    "  start = len(df_work)\n",
    "  \n",
    "  df_work.drop_duplicates(inplace=True)\n",
    "  \n",
    "  finish = len(df_work)\n",
    "  print(f\"중복 데이터 처리 : {start} - {start-finish} -> {finish}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 누락 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_missing(df_work: pd.DataFrame):\n",
    "  from sklearn.impute import KNNImputer\n",
    "\n",
    "  start_missing = df_work.isnull().sum()\n",
    "  start_missing = start_missing[start_missing > 0].to_dict()\n",
    "\n",
    "  total = col_mapping(df_work)\n",
    "  numeric_mapping(df_work, total, False)\n",
    "\n",
    "  numeric_cols = df_work.select_dtypes(include='number').columns\n",
    "  df_numeric = df_work[numeric_cols]\n",
    "\n",
    "  imputer = KNNImputer(n_neighbors=3)\n",
    "  df_imputed_numeric = pd.DataFrame(imputer.fit_transform(df_numeric), columns=numeric_cols, index=df_numeric.index)\n",
    "\n",
    "  df_work[numeric_cols] = df_imputed_numeric\n",
    "  \n",
    "  numeric_mapping(df_work, total, True)\n",
    "  \n",
    "  finish_missing = df_work.isnull().sum()\n",
    "  finish_missing = finish_missing[finish_missing > 0].to_dict()\n",
    "  print(f\"누락 데이터 처리 후: {start_missing} -> {finish_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_outlier(df_work: pd.DataFrame):\n",
    "  first = len(df_work)\n",
    "\n",
    "  total = col_mapping(df_work)\n",
    "  numeric_mapping(df_work, total, False)\n",
    "\n",
    "  numeric_cols = df_work.select_dtypes(include='number').columns\n",
    "\n",
    "  outlier_indices = set()\n",
    "  for col in numeric_cols:\n",
    "    Q1 = df_work[col].quantile(0.25)\n",
    "    Q3 = df_work[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_work[(df_work[col] < lower_bound) | (df_work[col] > upper_bound)].index\n",
    "    outlier_indices.update(outliers)\n",
    "\n",
    "  df_work.drop(index=outlier_indices, inplace=True)\n",
    "  df_work.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  numeric_mapping(df_work, total, True)\n",
    "\n",
    "  print(f\"이상치 처리 후: {first} - {len(outlier_indices)} = {len(df_work)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 젙처리\n",
    "all_df_preprocess = {}\n",
    "for sub_folder in all_df:\n",
    "  all_folder_df_preprocess = []\n",
    "  print(f\"=========={sub_folder}==========\")\n",
    "  for df, source in zip(all_df[sub_folder], all_source[sub_folder]):\n",
    "    df_preprocess = df.copy()\n",
    "    print(\"=====================================\")\n",
    "    print(f\"{source} - Preprocess\")\n",
    "    drop_duplicates(df_preprocess)\n",
    "    processing_missing(df_preprocess)\n",
    "    processing_outlier(df_preprocess)\n",
    "    all_folder_df_preprocess.append(df_preprocess)\n",
    "  print(\"=====================================\")\n",
    "  all_df_preprocess[sub_folder] = all_folder_df_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 후 shape 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_folder in all_df_preprocess:\n",
    "  print(f\"=========={sub_folder}==========\")\n",
    "  for df, df_preprocess, source in zip(all_df[sub_folder], all_df_preprocess[sub_folder], all_source[sub_folder]):\n",
    "    before = f\"({df.shape[0]:<5}, {df.shape[1]})\"\n",
    "    after = f\"({df_preprocess.shape[0]:<5}, {df_preprocess.shape[1]})\"\n",
    "    print(f\"{source:<15} : {before} -> {after}\")\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
